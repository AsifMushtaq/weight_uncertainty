[default]
# Batch size during training
batch_size = 35
# Size for hidden dimension
hidden_dim = 128
# Number of layers in LSTM
num_layers = 2
sigma_prior = 0.20
# do you want to clip the norm of gradients during training? Make larger than zero to enable
clip_norm = 10.0
# Which optimizer to use. Use 'sgd' or 'adam'
optimizer_name = adam
# learning rate
learning_rate = 0.0025
# Maximum number of training steps
max_steps = 15000


[direc]
data_direc_ucr = /home/rob/Dropbox/ml_projects/LSTM/UCR_TS_Archive_2015
data_direc_cifar = /home/rob/Dropbox/ml_projects/segm/data/cifar
data_direc_mnist = /home/rob/Dropbox/ml_projects/bayes_nn/bayes_nn/data/raw
log_direc = log
restore_direc = log/18-04-17__16:21:16/save/my-model
input_direc = input

